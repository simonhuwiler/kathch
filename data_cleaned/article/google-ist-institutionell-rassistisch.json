{"id": "google-ist-institutionell-rassistisch", "tag": "Zitat", "tag2": "Zitat", "title": "Google ist «institutionell rassistisch»", "text": "\n«Wenn ich für ein grosses Unternehmen wie Google arbeite, verbessere ich dann Dinge? Oder legitimiere ich schlechtes Verhalten und verschlimmere sie?», sagte Timnit Gebru. Sie arbeitete für Google als Top-Forscherin im Bereich Ethik und künstliche Intelligenz (KI).\nDiskriminierende Sprache\nEthisch besonders heikel ist das «Natural Language Processing». Laut NZZ handelt es sich um «ein Feld der KI, das sich mit Sprache befasst – also mit Programmen, die mit Sprache umgehen: übersetzen, Texte codieren oder zusammenfassen.Für Google ist das das Herzstück seines Angebots, einschliesslich der Google-Suche. Gebru und ihre Kolleginnen thematisieren in der Abhandlung die Probleme, die mit solchen Programmen einhergehen. So verbraucht etwa die Analyse grosser Datenmengen sehr viel Energie. Und werden diese Modelle mit diskriminierender Sprache etwa aus dem Internet trainiert, haben sie später einen ebensolchen Bias. (…)\nVorwurf: Google benachteiligt Nichtweisse \nGebru ist eine der bekanntesten Forscherinnen in Sachen Ethik bei der künstlichen Intelligenz. Sie war zum Beispiel an einer Studie beteiligt, die zeigt, dass kommerzielle Gesichtserkennungssysteme beim Erkennen schwarzer Frauen viel öfter danebenliegen als bei Weissen und bei Männern, weil diese Gruppe in den Datensätzen unterrepräsentiert ist, mit denen die Programme trainiert werden. Bei Google setzte Gebru sich neben der Forschung für mehr Diversität ein, und sie gründete die Organisation Black in AI mit. (…)\nGebru hat nun für sich eine Antwort auf die Frage gefunden, ob ihre Arbeit für Google Dinge verbessere. Sie geht mittlerweile so weit und sagt, dass Google «institutionell rassistisch» sei – also Nichtweisse benachteilige und ihre Einwände nicht ernst nehme. Inwiefern diese Vorwürfe berechtigt sind, ist von aussen schwer nachzuvollziehen. Die Diskussion wirft jedenfalls kein gutes Licht auf den Konzern, der sich einst die Losung «Don’t be evil» gegeben hat.»\nRuth Fulterer und Jenni Thier berichten in der «NZZ» über den Rausschmiss der Spitzenforscherin Timnit Gebru. (rr)\n\n\nKünstliche Intelligenz als stochastische Papageien\n\n\n© Katholisches Medienzentrum, 18.12.2020\nDie Rechte sämtlicher Texte sind beim Katholischen Medienzentrum. Jede Weiterverbreitung ist honorarpflichtig. Die Speicherung in elektronischen Datenbanken ist nicht erlaubt.\n\n\n                            Möchten Sie diesen Artikel in Ihrem Medium weiterverwenden?Hier geht es zur\n                            › Bestellung einzelner Beiträge\n                            von kath.ch.\n                        \n\n\n", "date": "2020-12-18 08:05", "author": "Ethisch besonders heikel ist das «Natural Language Processing». Laut NZZ handelt es sich um «ein Feld der KI, das sich mit Sprache befasst – also mit Programmen, die mit Sprache umgehen: übersetzen, Texte codieren oder zusammenfassen.Für Google ist das das Herzstück seines Angebots, einschliesslich der Google-Suche. Gebru und ihre Kolleginnen thematisieren in der Abhandlung die Probleme, die mit solchen Programmen einhergehen. So verbraucht etwa die Analyse grosser Datenmengen sehr viel Energie. Und werden diese Modelle mit diskriminierender Sprache etwa aus dem Internet trainiert, haben sie später einen ebensolchen Bias. (…)"}