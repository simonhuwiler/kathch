{"id": "auch-die-beste-kuenstliche-intelligenz-ist-dumm-wie-knaeckebrot", "tag": "Vatikan", "tag2": "Vatikan", "title": "«Beste künstliche Intelligenz dumm wie Knäckebrot»", "text": "\nEin Vatikan-Workshop mit Experten aus aller Welt soll einen Ethik-Leitfaden zu künstlicher Intelligenz erarbeiten. Medienethik-Professor Alexander Filipovic (45) erläutert im CIC-Interview, ob man Maschinen tatsächlich so etwas wie Moral beibringen kann.\nAlexander Pitz\nAlexander Filipovic, erklären Sie doch bitte mal, wieso das Thema künstliche Intelligenz für die katholische Kirche so bedeutsam ist?\nAlexander Filipovic: Da die Kirche auch von dieser Welt ist,\nmuss sie sich damit beschäftigen. Gerade aus sozialethischer Perspektive ist es\nwichtig, die Zeichen der Zeit nicht ausser Acht zu lassen. Da gehören die neuen\ndigitalen Techniken zweifellos dazu. Die Aufgabe besteht nun darin – wie es so\nschön heisst – solche Zeichen im Lichte des Evangeliums zu deuten. Es geht von\nmöglichen Auswirkungen auf den Glauben bis hin zum Selbstverständnis des\nMenschen. Die Kirche sollte sich also unbedingt mit diesem Thema\nauseinandersetzen.\nIch würde nicht sagen, dass ein weiterer Kodex das wichtigste Ziel dieser Konferenz ist.\nDer aktuelle Experten-Workshop im Vatikan soll einen Ethik-Kodex zu künstlicher Intelligenz erarbeiten. Was sind die grössten Schwierigkeiten bei diesem Projekt?\nFilipovic: Das grösste Problem ist vermutlich, dass es schon\nhaufenweise solcher KI-Codices gibt. Es liegen sogar Studien dazu vor. Das\nErgebnis ist wenig überraschend: Eigentlich steht immer das Gleiche drin.\nManchmal ist allenfalls die Reihenfolge der thematisierten Wertbegriffe wie\nFreiheit, Transparenz oder Gemeinwohl ein wenig anders. Ich würde daher nicht\nsagen, dass ein weiterer Kodex das wichtigste Ziel dieser Konferenz ist.\nVielmehr geht es darum, die weltweite Bewegung zu unterstützen, die über einen\nverantwortungsvollen Umgang mit der machtvollen KI nachdenkt.\nWie kann es gelingen, die vielen widerstrebenden Interessen unter einen Hut zu bringen? China und die USA etwa haben sicherlich unterschiedliche Vorstellungen, wie ein verantwortungsvoller Umgang aussehen könnte.\nFilipovic: Wenn man sich zunächst nur die Begriffe ansieht,\ndie unsere KI-Systeme leiten sollen, sind die Unterschiede zwischen China,\nEuropa und den USA gar nicht so gross. Das internationale Problem liegt darin,\ndass die Länder versuchen, eine Führerschaft in Sachen KI zu erlangen. Das\nzerstört das Miteinander. Jeder will Erster sein und bekämpft die anderen. Die\nStaaten und Blöcke bringen sicher derzeit ganz massiv in Stellung. Diese\ngeopolitischen Vorgänge im Rennen um die KI-Führerschaft sind eine\nsozialethisch wichtige Thematik.\nIn Ihrem Vortrag am Mittwoch im Vatikan haben Sie kritisiert, dass KI als Machtinstrument genutzt werde – sei es in Wirtschaft, Forschung oder für militärische Zwecke. Was kann man tun, um diesem ethisch bedenklichen Trend entgegenzuwirken?\nFilipovic: Das ist alles nicht so einfach. Die gesamte\nRegulation von Technik ist unglaublich schwierig, weil eine grosse ökonomische\nDynamik dahintersteht und natürlich viel Geld verdient werden kann. Je nachdem,\nwie man das Verhältnis von Politik und Wirtschaft sieht, kann es problematisch\nwerden. In Deutschland gibt es ja ebenfalls bestimmte Parteien, die einer\nRegulierung von wirtschaftlichen Prozessen eher kritisch gegenüberstehen.\nWichtig finde ich, jenseits von parteipolitischen Präferenzen, dass wir in\ndieser Frage eine Gestaltungsperspektive einnehmen.\nWie meinen Sie das?\nFilipovic: Wir dürfen nicht einfach sagen: KI passiert mit\nuns. Sondern: Wir sind in der Lage, zu gestalten und zu bestimmen, wie\nkünstliche Intelligenz eingesetzt werden kann. Das kann meines Erachtens nur\npolitisch geschehen – nicht nur durch Gesetze, sondern etwa durch Anreizsysteme\nfür die Entwicklung guter KI, die dem Menschen wirklich hilft. Angesichts der\ngeopolitischen Lage wird es allerdings schwierig, zu solchen Übereinkünften zu\ngelangen. Wichtig wäre es, zumindest in den besonders heiklen Fällen wie bei\nletalen autonomen Waffensystemen oder beim Schutz der Privatsphäre zu\neinheitlichen Regelungen zu kommen.\nMan kann den Maschinen tatsächlich so etwas wie Moral einprogrammieren. \nNoch eine praktische Frage: Kann man einer Maschine, die in den nächsten Jahren wichtige Aufgaben übernehmen wird, die bisher von Menschen erledigt werden, ethische Prinzipien einprogrammieren?\nFilipovic: Man kann den Maschinen tatsächlich so etwas wie\nMoral einprogrammieren. Das können freilich nur Algorithmen sein. Dabei kann\ndann mal etwas herauskommen, das wir für moralisch relevant halten. Aber\nletztlich sind moralisch vertretbare Entscheidungen nur in einer Interaktion\nmit dem Menschen möglich. Wenn zum Beispiel eine Diagnose-Maschine einen Tumor\nerkennen sollte, wird sie auf Basis vieler Daten wahrscheinlich zu guten\nErgebnissen kommen. Doch das ist keine verantwortbare Entscheidung. Die muss\nein Arzt treffen. Denn auch die beste künstliche Intelligenz ist im Grunde dumm\nwie Knäckebrot. (kna)\n\n© Katholisches Medienzentrum, 28.02.2020\nDie Rechte sämtlicher Texte sind beim Katholischen Medienzentrum. Jede Weiterverbreitung ist honorarpflichtig. Die Speicherung in elektronischen Datenbanken ist nicht erlaubt.\n\n\n                            Möchten Sie diesen Artikel in Ihrem Medium weiterverwenden?Hier geht es zur\n                            › Bestellung einzelner Beiträge\n                            von kath.ch.\n                        \n\n\n", "date": "2020-02-28 12:15", "author": "Alexander Pitz"}